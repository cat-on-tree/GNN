import pandas as pd
import numpy as np
from tqdm import tqdm
import os

# ==========================================
# 1. é…ç½®åŒºåŸŸ
# ==========================================
# åŸå§‹æµ‹è¯•é›†è·¯å¾„ (é™¤å» NA åçš„ mapping æ–‡ä»¶)
input_clean_path = "../data/benchmark/Kaggle_drug_repositioning/full_mapping_without_na.csv"

# è®­ç»ƒé›†å’ŒéªŒè¯é›†è·¯å¾„ (ç”¨äºé˜²æ³„æ¼æ£€æŸ¥)
train_path = "../data/benchmark/PrimeKG/train_edges.csv"
val_path = "../data/benchmark/PrimeKG/val_edges.csv"

# èŠ‚ç‚¹è¡¨ (ç”¨äºè·å–æ€»èŠ‚ç‚¹æ•°)
nodes_path = "../data/benchmark/PrimeKG/nodes.csv"

# è¾“å‡ºç›®å½•
save_dir = "../data/benchmark/Kaggle_drug_repositioning"
os.makedirs(save_dir, exist_ok=True)

# ç›®æ ‡å…³ç³»ç±»å‹ (PrimeKG ä¸­è¯ç‰©æ²»ç–—ç–¾ç—…çš„å…³ç³»é€šå¸¸å« indication)
target_relation = 'indication'

# æŠ½æ ·å‚æ•°
num_test_samples = 500  # æ­£æ ·æœ¬æ•°é‡ (è´Ÿæ ·æœ¬ä¼šè‡ªåŠ¨ç”Ÿæˆç›¸åŒæ•°é‡)
seed = 42  # å›ºå®šéšæœºç§å­
rng = np.random.default_rng(seed)

# ==========================================
# 2. é¢„æ£€æŸ¥
# ==========================================
print(">>> Step 0: Checking prerequisites...")
try:
    df_train = pd.read_csv(train_path)
    if target_relation not in df_train['relation'].unique():
        print(f"âŒ é”™è¯¯: è®­ç»ƒé›†ä¸­ä¸å­˜åœ¨å…³ç³» '{target_relation}'ã€‚è¯·æ£€æŸ¥å…³ç³»åç§°ã€‚")
        exit(1)
    print(f"âœ… ç¡®è®¤: è®­ç»ƒé›†ä¸­åŒ…å« '{target_relation}'")
except FileNotFoundError:
    print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°è®­ç»ƒé›†æ–‡ä»¶ {train_path}")
    exit(1)

# ==========================================
# 3. è¯»å–å¹¶æ ‡å‡†åŒ–æµ‹è¯•é›†
# ==========================================
print("\n>>> Step 1: Loading test mapping...")
df_test = pd.read_csv(input_clean_path)
# ç¡®ä¿ ID ä¸ºæ•´æ•°
df_test['x_index'] = df_test['x_index'].astype(int)
df_test['y_index'] = df_test['y_index'].astype(int)

# æ„é€ åˆå§‹æ­£æ ·æœ¬æ± 
test_pos_all = pd.DataFrame({
    'relation': target_relation,
    'x_index': df_test['x_index'],
    'y_index': df_test['y_index'],
    'label': 1
})
print(f"Original test pairs loaded: {len(test_pos_all)}")

# ==========================================
# 4. é˜²æ³„æ¼æ¸…æ´— (Leakage Removal)
# ==========================================
print("\n>>> Step 2: Removing edges that exist in Train/Val...")
try:
    df_val = pd.read_csv(val_path)
except FileNotFoundError:
    print("âŒ æ‰¾ä¸åˆ°éªŒè¯é›†")
    exit(1)

# åˆå¹¶è®­ç»ƒå’ŒéªŒè¯é›†çš„æ­£æ ·æœ¬ï¼Œæ„å»ºâ€œå·²å­˜åœ¨è¾¹â€çš„é›†åˆ
existing_pos = pd.concat([
    df_train[df_train['label'] == 1],
    df_val[df_val['label'] == 1]
])

# ä½¿ç”¨ set å­˜å‚¨ (relation, min_id, max_id) ä»¥å¤„ç†æ½œåœ¨çš„æ— å‘æ€§æˆ–æ–¹å‘æ··æ·†
existing_set = set(zip(
    existing_pos['relation'],
    existing_pos[['x_index', 'y_index']].min(axis=1),
    existing_pos[['x_index', 'y_index']].max(axis=1)
))

# è¿‡æ»¤æµ‹è¯•é›†
valid_rows = []
leak_count = 0
for _, row in tqdm(test_pos_all.iterrows(), total=len(test_pos_all), desc="Checking leakage"):
    # æ£€æŸ¥å½“å‰æµ‹è¯•è¾¹æ˜¯å¦å·²å­˜åœ¨
    check_tuple = (row['relation'], min(row['x_index'], row['y_index']), max(row['x_index'], row['y_index']))
    if check_tuple in existing_set:
        leak_count += 1
    else:
        valid_rows.append(row)

test_pos_clean = pd.DataFrame(valid_rows).reset_index(drop=True)
print(f"Removed {leak_count} leaked edges.")
print(f"Clean test candidates available: {len(test_pos_clean)}")

# ==========================================
# 5. åŒå‘æœ€å¤§è¦†ç›–æŠ½æ · (Bi-directional Sampling)
# ==========================================
print(f"\n>>> Step 3: Sampling {num_test_samples} positives (Maximizing Drug & Disease Diversity)...")

if len(test_pos_clean) <= num_test_samples:
    print(f"âš ï¸ å¯ç”¨æ ·æœ¬ä¸è¶³ {num_test_samples}ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®ã€‚")
    test_pos_sampled = test_pos_clean
else:
    # å‡†å¤‡å·¥ä½œ
    pool = test_pos_clean.copy()
    # å…ˆæ‰“ä¹±æ± å­ï¼Œä¿è¯éšæœºæ€§
    pool = pool.sample(frac=1, random_state=seed).reset_index(drop=True)

    final_selection = []
    covered_drugs = set()
    covered_diseases = set()

    # è´ªå¿ƒç­–ç•¥ï¼šäº¤æ›¿å¯»æ‰¾èƒ½å¸¦æ¥â€œæ–°è¯ç‰©â€æˆ–â€œæ–°ç–¾ç—…â€è¦†ç›–çš„æ ·æœ¬
    turn = 0  # 0: ä¼˜å…ˆæ‰¾æ–° Drug, 1: ä¼˜å…ˆæ‰¾æ–° Disease

    # è¿›åº¦æ¡
    pbar = tqdm(total=num_test_samples, desc="Sampling")

    while len(final_selection) < num_test_samples and not pool.empty:

        found_in_this_scan = False
        rows_to_remove = []

        # éå†å½“å‰æ± å­
        for idx, row in pool.iterrows():
            if len(final_selection) >= num_test_samples:
                break

            drug = row['x_index']
            disease = row['y_index']

            is_new_drug = drug not in covered_drugs
            is_new_disease = disease not in covered_diseases

            should_pick = False

            # å†³ç­–é€»è¾‘
            if turn == 0:  # è½®åˆ° Drug å›åˆ
                if is_new_drug:
                    should_pick = True
                elif is_new_disease and len(final_selection) < num_test_samples * 0.9:
                    # å¦‚æœæ²¡æ–°è¯äº†ï¼Œæœ‰æ–°ç—…ä¹Ÿè¡Œï¼Œä½†ç•™ç‚¹ä½™åœ°
                    should_pick = True
            else:  # è½®åˆ° Disease å›åˆ
                if is_new_disease:
                    should_pick = True
                elif is_new_drug and len(final_selection) < num_test_samples * 0.9:
                    should_pick = True

            if should_pick:
                final_selection.append(row)
                covered_drugs.add(drug)
                covered_diseases.add(disease)
                rows_to_remove.append(idx)
                pbar.update(1)
                found_in_this_scan = True

                # åˆ‡æ¢å›åˆ
                turn = 1 - turn

        # ä»æ± ä¸­ç§»é™¤å·²é€‰
        if rows_to_remove:
            pool = pool.drop(rows_to_remove)

        # å¦‚æœä¸€æ•´è½®æ‰«æéƒ½æ²¡æ‰¾åˆ°èƒ½å¢åŠ è¦†ç›–ç‡çš„æ ·æœ¬ï¼ˆè¯´æ˜å‰©ä¸‹çš„å…¨æ˜¯æ—§è¯æ—§ç—…ï¼‰
        # ç›´æ¥éšæœºå¡«å……å‰©ä½™åé¢
        if not found_in_this_scan:
            remaining_cnt = num_test_samples - len(final_selection)
            if remaining_cnt > 0:
                # print(f"Coverage saturated. Randomly filling {remaining_cnt}...")
                random_fill = pool.sample(n=remaining_cnt, random_state=seed)
                for _, row in random_fill.iterrows():
                    final_selection.append(row)
                    pbar.update(1)
            break

    pbar.close()
    test_pos_sampled = pd.DataFrame(final_selection).reset_index(drop=True)

    # æ‰“å°è¦†ç›–ç»Ÿè®¡
    n_drugs = test_pos_sampled['x_index'].nunique()
    n_diseases = test_pos_sampled['y_index'].nunique()
    print(f"âœ… æŠ½æ ·å®Œæˆã€‚è¦†ç›–ç»Ÿè®¡: {n_drugs} ç§è¯ç‰©, {n_diseases} ç§ç–¾ç—…ã€‚")

# ==========================================
# 6. ç”Ÿæˆ Hard Negatives
# ==========================================
print("\n>>> Step 4: Generating Hard Negatives...")
nodes_df = pd.read_csv(nodes_path)
num_nodes = int(nodes_df['node_index'].max() + 1)

# æ„å»ºå…¨å±€ç¦å¿Œè¡¨ (Global Ban List)
# åŒ…å«: è®­ç»ƒé›† + éªŒè¯é›† + æµ‹è¯•é›†æ‰€æœ‰å€™é€‰æ­£ä¾‹ (ä¸ä»…ä»…æ˜¯æŠ½ä¸­çš„è¿™500ä¸ª)
# ç›®çš„: é˜²æ­¢ç”Ÿæˆçš„è´Ÿä¾‹æ°å¥½æ˜¯çœŸå®çš„é˜³æ€§æ ·æœ¬
test_pos_set = set(zip(
    test_pos_clean['relation'],
    test_pos_clean[['x_index', 'y_index']].min(axis=1),
    test_pos_clean[['x_index', 'y_index']].max(axis=1)
))
global_ban_set = existing_set.union(test_pos_set)

neg_src = []
neg_dst = []
neg_rel = []

src_arr = test_pos_sampled['x_index'].values
rel_arr = test_pos_sampled['relation'].values

# éšæœºç”Ÿæˆåˆå§‹è´ŸèŠ‚ç‚¹æ± 
b_neg_dst = rng.integers(0, num_nodes, size=len(src_arr))

for j in tqdm(range(len(src_arr)), desc="Negative Sampling"):
    h, t_fake, r = src_arr[j], b_neg_dst[j], rel_arr[j]

    check_u, check_v = min(h, t_fake), max(h, t_fake)

    # æ‹’ç»é‡‡æ ·å¾ªç¯
    # å¦‚æœç”Ÿæˆçš„ (h, t_fake) åœ¨ç¦å¿Œè¡¨ä¸­ï¼Œæˆ–è€…æ˜¯è‡ªç¯ï¼Œå°±é‡é‡‡
    while check_u == check_v or (r, check_u, check_v) in global_ban_set:
        t_fake = rng.integers(0, num_nodes)
        check_u, check_v = min(h, t_fake), max(h, t_fake)

    neg_src.append(h)
    neg_dst.append(t_fake)
    neg_rel.append(r)

test_neg = pd.DataFrame({
    'relation': neg_rel,
    'x_index': neg_src,
    'y_index': neg_dst,
    'label': 0
})

# ==========================================
# 7. åˆå¹¶ä¸ä¿å­˜
# ==========================================
print("\n>>> Step 5: Saving final dataset...")

# åˆå¹¶æ­£è´Ÿæ ·æœ¬
test_final = pd.concat([test_pos_sampled, test_neg], ignore_index=True)

# æœ€ç»ˆæ‰“ä¹±
test_final = test_final.sample(frac=1, random_state=seed).reset_index(drop=True)

output_filename = "test.csv"
output_path = os.path.join(save_dir, output_filename)

test_final.to_csv(output_path, index=False)

print(f"ğŸ‰ æˆåŠŸ! æ–‡ä»¶å·²ä¿å­˜è‡³: {output_path}")
print(f"   æ€»æ ·æœ¬æ•°: {len(test_final)}")
print(f"   æ­£æ ·æœ¬ (Label=1): {len(test_pos_sampled)}")
print(f"   è´Ÿæ ·æœ¬ (Label=0): {len(test_neg)}")
print("Done.")